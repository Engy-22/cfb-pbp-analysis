{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import html\n",
    "import os.path\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEC',\n",
       " 'Pac-12',\n",
       " 'FBS Independents',\n",
       " 'Big 12',\n",
       " 'ACC',\n",
       " 'Big Ten',\n",
       " 'Mountain West',\n",
       " 'Mid-American',\n",
       " 'Sun Belt',\n",
       " 'Conference USA',\n",
       " 'American Athletic']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p5 = [\"SEC\",\"Pac-12\",\"FBS Independents\",\"Big 12\", \"ACC\", \"Big Ten\"]\n",
    "g5 = [\"Mountain West\", \"Mid-American\",\"Sun Belt\",\"Conference USA\",\"American Athletic\"]\n",
    "fbs = p5 + g5\n",
    "fbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveCfbData(endpoint, team, year, week):\n",
    "    file_path = f\"data/{endpoint if (endpoint != 'plays') else 'pbp'}/{endpoint[:-1] if (endpoint != 'plays') else 'pbp'}-data-{team.lower().replace(' ','-')}-{year}-wk{week}.json\"\n",
    "    if (os.path.exists(file_path)):\n",
    "        return file_path\n",
    "    res = requests.get(f\"https://api.collegefootballdata.com/{endpoint}?seasonType=regular&year={year}&team={html.escape(team)}&week={week}\")\n",
    "    content = res.json()\n",
    "#     with open(file_path, 'w') as f:\n",
    "#         json.dump(content, f)\n",
    "    return json.dumps(content)\n",
    "\n",
    "def retrieveRemoteCfbGame(game_id, year):\n",
    "    file_path = f\"data/games/game-data-{game_id}.json\"\n",
    "    if (os.path.exists(file_path)):\n",
    "        return file_path\n",
    "    res = requests.get(f\"https://api.collegefootballdata.com/games?year={year}&seasonType=regular&id={game_id}\")\n",
    "    content = res.json()\n",
    "#     with open(file_path, 'w') as f:\n",
    "#         json.dump(content, f)\n",
    "    return json.dumps(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data retrieval\n",
    "teams = pd.read_csv(\"data/teams/2019.csv\", encoding = 'latin-1')\n",
    "ep_data = pd.read_csv(\"results/ep.csv\", encoding = 'latin-1')\n",
    "\n",
    "base_drives = pd.DataFrame()\n",
    "games = pd.DataFrame()\n",
    "pbp_data = pd.DataFrame()\n",
    "\n",
    "def retrieveCfbDataFile(endpoint, year):\n",
    "    return pd.read_csv(f\"data/{endpoint}/{year}.csv\", encoding='latin-1')\n",
    "\n",
    "for i in range(2012, 2020):\n",
    "    drive = retrieveCfbDataFile('drives',i)\n",
    "    drive['year'] = i\n",
    "    base_drives = base_drives.append(drive, sort=False)\n",
    "    \n",
    "    gm = retrieveCfbDataFile('games',i)\n",
    "    gm['year'] = i\n",
    "    games = games.append(gm, sort=False)\n",
    "    \n",
    "    plys = retrieveCfbDataFile('pbp',i)\n",
    "    plys['year'] = i\n",
    "    pbp_data = pbp_data.append(plys, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 6644\n",
      "Total Drives: 171692\n",
      "Total Plays: 1210147\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Games: {len(games)}\")\n",
    "print(f\"Total Drives: {len(base_drives)}\")\n",
    "print(f\"Total Plays: {len(pbp_data)}\")\n",
    "\n",
    "# print(f\"2016 Drives: {len(base_drives[base_drives.game_id == 400868979])}\")\n",
    "# base_drives[base_drives.offense == 'Ole Miss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Drives: 170795\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "\n",
    "games.reset_index(inplace = True) \n",
    "pbp_data.reset_index(inplace = True) \n",
    "base_drives.reset_index(inplace = True) \n",
    "\n",
    "base_drives = base_drives[\n",
    "    (~base_drives.drive_result.isin(['Uncategorized']))\n",
    "]\n",
    "base_drives.drop(['offense_conference','start_time.minutes','start_time.seconds','end_time.minutes','end_time.seconds','defense_conference','elapsed.seconds','elapsed.minutes'], axis = 1, inplace=True) \n",
    "drives = pd.merge(base_drives, games[['id','away_team','home_team']], left_on='game_id', right_on='id', how='right')\n",
    "drives.rename(columns={'id_x':'drive_id'}, inplace=True)\n",
    "drives.drop(['id_y'], axis = 1, inplace=True)\n",
    "drives.dropna(inplace=True)\n",
    "print(f\"Clean Drives: {len(drives)}\")\n",
    "\n",
    "drives.loc[\n",
    "    drives.offense == drives.away_team, ['start_yardline']\n",
    "] = 100 - drives.start_yardline\n",
    "drives.loc[\n",
    "    drives.offense == drives.away_team, ['end_yardline']\n",
    "] = 100 - drives.end_yardline\n",
    "pbp_data = pbp_data[\n",
    "    (pbp_data.down != 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbp_data.distance = pbp_data.distance.astype(float)\n",
    "\n",
    "st_types = [\"Blocked Field Goal\",\"Blocked Punt\",\"Missed Field Goal Return\",\"Blocked Punt Touchdown\",\"Missed Field Goal Return Touchdown\",\"Extra Point Missed\",\"Extra Point Good\",\"Kickoff\",\"Kickoff Return (Offense)\",\"Kickoff Return Touchdown\",\"Punt\", \"Field Goal Good\",\"Field Goal Missed\",\"Defensive 2pt Conversion\",\"2pt Conversion\",\"Blocked Field Goal Touchdown\",\"Punt Return Touchdown\"]\n",
    "# Ignore some types of plays cause they're special teams and weird\n",
    "ignore_types = [\"Timeout\",\"End of Half\",\"End of Game\",\"Uncategorized\",\"Penalty\",\"Safety\",\"placeholder\",\"End of Period\", \"End Period\"]\n",
    "off_play_types = pbp_data[(~(pbp_data.play_type.isin(ignore_types))) & (~(pbp_data.play_type.isin(st_types)))].play_type.drop_duplicates().tolist()\n",
    "pbp_data = pbp_data[~(pbp_data.play_type.isin(ignore_types)) & ~(pbp_data.play_text.str.contains(\"Penalty\").astype(bool))]\n",
    "bad_types = [\"Interception\",\"Pass Interception Return\",\"Interception Return Touchdown\",'Fumble Recovery (Opponent)','Sack','Fumble Return Touchdown']\n",
    "pbp_data.loc[\n",
    "    ((pbp_data.play_type.isin(bad_types)))\n",
    "     & (~pbp_data.play_type.str.contains('Sack')) ,['yards_gained']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pass Incompletion',\n",
       " 'Pass Completion',\n",
       " 'Rush',\n",
       " 'Sack',\n",
       " 'Pass Interception',\n",
       " 'Pass',\n",
       " 'Pass Reception',\n",
       " 'Fumble Recovery (Opponent)',\n",
       " 'Passing Touchdown',\n",
       " 'Fumble Recovery (Own)',\n",
       " 'Rushing Touchdown',\n",
       " 'Pass Interception Return',\n",
       " 'Fumble Return Touchdown',\n",
       " 'Interception Return Touchdown',\n",
       " 'Interception']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_play_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "if 'EqPPP' not in pbp_data.columns:\n",
    "    pbp_data[\"EqPPP\"] = pbp_data.apply(lambda x: 0 if (x.play_type in st_types) else (ep_data.iloc[max(min(100, (x.yard_line + x.yards_gained)), 0)].ep - ep_data.iloc[max(min(x.yard_line, 100), 0)].ep), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_division(num1, num2):\n",
    "    if num2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num1 / num2\n",
    "    \n",
    "def calculate_success_in_scoring_opps(pbp, opps, team):\n",
    "    opp_ids = opps.drive_id.unique()\n",
    "    success = 0\n",
    "    total = 0\n",
    "    for opp_id in opp_ids:\n",
    "        opp_set = pbp[(pbp.play_type.isin(off_play_types)) & (pbp.drive_id == opp_id) & (pbp.offense == team)]\n",
    "        opp_s_rate = verify_division(len(opp_set[opp_set.play_successful == True]), len(opp_set))\n",
    "        success += len(opp_set[opp_set.play_successful == True])\n",
    "        total += len(opp_set)\n",
    "    s_rate = 0 if total == 0 else (success / total)\n",
    "    return s_rate\n",
    "\n",
    "def calculate_score_value(drv):\n",
    "    if (drv.drive_result == 'TD'):\n",
    "        return 7\n",
    "    elif (drv.drive_result == 'FG'):\n",
    "        return 3\n",
    "    elif (drv.drive_result == 'SAFETY'):\n",
    "        return -2\n",
    "    elif ((drv.drive_result == 'INT TD') | (drv.drive_result == 'FUMBLE TD')):\n",
    "        return -7\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_ppd_in_scoring_opps(opps, team):\n",
    "    scores = 0\n",
    "    total = len(opps)\n",
    "    scores = opps.apply(lambda x: calculate_score_value(x), axis = 1)\n",
    "    ppd = 0 if total == 0 else (sum(scores) / total)\n",
    "    return ppd\n",
    "    \n",
    "def is_successful(down, distance, yards_gained, play_type):\n",
    "    if (play_type in bad_types):\n",
    "        return False \n",
    "    if ((down == 1) & (yards_gained >= (0.5 * distance))):\n",
    "        return True\n",
    "    elif ((down == 2)) & (yards_gained >= (0.7 * distance)):\n",
    "        return True\n",
    "    elif ((down == 3) & (yards_gained >= distance)):\n",
    "        return True\n",
    "    elif ((down == 4) & (yards_gained >= distance)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_successful_vector(play):\n",
    "    if (play.play_type in bad_types):\n",
    "        return False \n",
    "    if ((play.down == 1) & (play.yards_gained >= (0.5 * play.distance))):\n",
    "        return True\n",
    "    elif ((play.down == 2)) & (play.yards_gained >= (0.7 * play.distance)):\n",
    "        return True\n",
    "    elif ((play.down == 3) & (play.yards_gained >= play.distance)):\n",
    "        return True\n",
    "    elif ((play.down == 4) & (play.yards_gained >= play.distance)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_explosive(yards_gained):\n",
    "    if (yards_gained >= 15):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "if 'play_explosive' not in pbp_data.columns:\n",
    "    pbp_data['play_explosive'] = pbp_data.apply(lambda x: False if (x.play_type in st_types) else (x.yards_gained >= 15), axis=1)\n",
    "if 'play_successful' not in pbp_data.columns:\n",
    "    pbp_data['play_successful'] = pbp_data.apply(lambda x: False if (x.play_type in st_types) else (is_successful_vector(x)), axis=1)\n",
    "    \n",
    "def calculate_success_rate(pbp, exclude_types):\n",
    "    return verify_division(len(pbp[(pbp.play_successful == True) & (~pbp.play_type.isin(exclude_types))]), len(pbp[(~pbp.play_type.isin(exclude_types))]))\n",
    "    \n",
    "def calculate_exp_rate(pbp, exclude_types):\n",
    "    return verify_division(len(pbp[(pbp.play_explosive == True) & (~pbp.play_type.isin(exclude_types))]), len(pbp[(~pbp.play_type.isin(exclude_types))]))\n",
    "    \n",
    "standard_downs = pbp_data[\n",
    "    (pbp_data.down == 1)\n",
    "    | ((pbp_data.down == 2) & (pbp_data.distance <= 7))\n",
    "    | ((pbp_data.down == 3) & (pbp_data.distance <= 4))\n",
    "    | ((pbp_data.down == 4) & (pbp_data.distance <= 4)) \n",
    "]\n",
    "\n",
    "passing_downs = pbp_data[\n",
    "    ((pbp_data.down == 2) & (pbp_data.distance >= 8))\n",
    "    | ((pbp_data.down == 3) & (pbp_data.distance >= 5))\n",
    "    | ((pbp_data.down == 4) & (pbp_data.distance >= 5)) \n",
    "]\n",
    "\n",
    "pass_types = [\"Pass Reception\",\"Pass Incompletion\",\"Passing Touchdown\",\"Interception\",\"Pass Interception Return\",\"Interception Return Touchdown\",\"Sack\"]\n",
    "rush_types = [\"Rush\",\"Rushing Touchdown\",'Fumble Recovery (Opponent)','Fumble Return Touchdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['OffSR','OffER','FP','OppRate','OppEff','OppPPD','PPD','OppSR','YPP', 'ExpTO', 'ActualTO', 'AvgEqPPP', 'TotalEqPPP','IsoPPP','HavocRate','FGEff']\n",
    "\n",
    "# somewhat defined here: https://www.footballstudyhall.com/2014/1/27/5349762/five-factors-college-football-efficiency-explosiveness-isoppp#\n",
    "def generate_iso_ppp(pbp, team):\n",
    "    base_success = pbp[(pbp.play_type.isin(off_play_types)) & (pbp.play_successful == True) & (pbp.offense == team)]\n",
    "    return base_success.EqPPP.mean() #verify_division(pbp.EqPPP.sum(), len(base_success))\n",
    "\n",
    "def generate_team_play_stats(pbp, team):\n",
    "    team_off_plays = pbp[(pbp.play_type.isin(off_play_types)) & (pbp.offense == team)]\n",
    "    off_sr = calculate_success_rate(team_off_plays, [])\n",
    "    off_er = calculate_exp_rate(team_off_plays, [])\n",
    "    ypp = verify_division(sum(team_off_plays.yards_gained), len(team_off_plays))\n",
    "    iso_ppp = generate_iso_ppp(team_off_plays, team)\n",
    "    avg_eqppp = team_off_plays.EqPPP.mean()\n",
    "    total_eqppp = team_off_plays.EqPPP.sum()\n",
    "    return pd.DataFrame({\n",
    "        'team': [team],\n",
    "        \"OffSR\": [off_sr],\n",
    "        \"OffER\" : [off_er],\n",
    "        \"YPP\" : [ypp],\n",
    "        \"IsoPPP\" : [iso_ppp],\n",
    "        \"AvgEqPPP\" : [avg_eqppp],\n",
    "        \"TotalEqPPP\" : [total_eqppp]\n",
    "    })\n",
    "\n",
    "def generate_team_drive_stats(drvs, pbp, gm, points, team):\n",
    "    team_drives = drvs[drvs.offense == team]\n",
    "    scoring_opps = team_drives[\n",
    "        ((team_drives.start_yardline + team_drives.yards) >= 60)\n",
    "    ]\n",
    "    avg_fp = verify_division(sum(team_drives.start_yardline), len(team_drives))\n",
    "    ppd = verify_division(points, len(team_drives))\n",
    "    opp_effcy = verify_division(len(scoring_opps[scoring_opps.scoring == True]), len(scoring_opps))\n",
    "    opp_rate = verify_division(len(scoring_opps), len(team_drives))\n",
    "    opp_sr = calculate_success_in_scoring_opps(pbp, scoring_opps, team)\n",
    "    opp_ppd = calculate_ppd_in_scoring_opps(scoring_opps, team)\n",
    "    return pd.DataFrame({\n",
    "        'team': [team],\n",
    "        'FP': [avg_fp],\n",
    "        'PPD': [ppd],\n",
    "        'OppEff': [opp_effcy],\n",
    "        'OppRate': [opp_rate],\n",
    "        'OppSR': [opp_sr],\n",
    "        'OppPPD': [opp_ppd]\n",
    "    })\n",
    "\n",
    "def calculate_havoc_rate(pbp, team):\n",
    "    team_havoc = pbp[(pbp.play_type.isin(off_play_types)) & (pbp.defense == team) & ((((pbp.play_type == 'Pass Incompletion')\n",
    "        & (pbp.play_text.str.contains('broken up', regex=False)))\n",
    "        | (pbp.play_type == 'Fumble Recovery (Opponent)')\n",
    "        | (pbp.play_type == 'Sack')\n",
    "        | (pbp.play_type.str.contains('Interception', regex=False))\n",
    "        | (pbp.yards_gained < 0))\n",
    "        & (pbp.play_type != 'Penalty'))]\n",
    "    return verify_division(len(team_havoc), len(pbp[(pbp.defense == team)]))\n",
    "\n",
    "def generate_team_turnover_stats(pbp, team):\n",
    "    adj_turnover_plays = pbp[\n",
    "        (pbp.play_type.isin(off_play_types))\n",
    "        & ((pbp.play_type.str.contains('Interception', regex=False))\n",
    "        | ((pbp.play_type == 'Pass Incompletion')\n",
    "        & (pbp.play_text.str.contains('broken up', regex=False)))\n",
    "        | (pbp.play_type.str.contains('Fumble', regex=False)))\n",
    "    ]\n",
    "\n",
    "    fum_plays = adj_turnover_plays[\n",
    "        (adj_turnover_plays.play_type.str.contains('Fumble', regex=False))\n",
    "    ]\n",
    "\n",
    "    # away_team Adj Turnovers\n",
    "    team_tos = adj_turnover_plays[\n",
    "        (adj_turnover_plays.offense == team)\n",
    "        | (adj_turnover_plays.defense == team)\n",
    "    ]\n",
    "\n",
    "    team_ints_off = team_tos[\n",
    "       (team_tos.play_type.str.contains('Interception', regex=False))\n",
    "        & (team_tos.offense == team)\n",
    "    ]\n",
    "\n",
    "    team_pds = team_tos[\n",
    "       (team_tos.play_type == 'Pass Incompletion')\n",
    "        & (team_tos.play_text.str.contains('broken up', regex=False))\n",
    "        & (team_tos.offense == team)\n",
    "    ]\n",
    "    \n",
    "    exp_to = (0.22 * (len(team_pds) + len(team_ints_off))) + (0.49 * len(fum_plays))\n",
    "    actual_to = len(team_ints_off) + len(fum_plays[(fum_plays.offense == team) & (fum_plays.play_type.str.contains('Fumble Recovery (Opponent)', regex=False))])\n",
    "    havoc = calculate_havoc_rate(pbp, team)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'team' : [team],\n",
    "        'ExpTO': [exp_to],\n",
    "        'ActualTO' : [actual_to],\n",
    "        'HavocRate': [havoc]\n",
    "    })\n",
    "\n",
    "def generate_team_special_teams_stats(pbp, team):\n",
    "    st_plays = pbp[(pbp.play_type.isin(st_types)) & (pbp.offense == team)]\n",
    "    \n",
    "    fg_plays = st_plays[st_plays.play_type.str.contains(\"Field Goal\")]\n",
    "    fg_made = fg_plays[fg_plays.play_type.str.contains(\"Good\")]\n",
    "    fg_eff = verify_division(len(fg_made), len(fg_plays))\n",
    "    \n",
    "    xp_plays = st_plays[st_plays.play_type.str.contains(\"Extra Point\")]\n",
    "    xp_made = xp_plays[xp_plays.play_type.str.contains(\"Good\")]\n",
    "    xp_eff = verify_division(len(xp_made), len(xp_plays))\n",
    "    \n",
    "#     kickoff_plays = st_plays[st_plays.play_type.str.contains(\"Kickoff\") & ~(st_plays.play_text.str.contains(\"on-side\"))]\n",
    "#     tmp = pd.DataFrame(data=kickoff_plays.play_text.str.extract('kickoff for (\\d+) yds', expand=True).astype(float))\n",
    "#     kickoff_distance = pd.DataFrame()\n",
    "#     kickoff_distance[\"Index\"] = tmp.index\n",
    "#     kickoff_distance[\"Yardline\"] = kickoff_distance.apply(lambda x: 50 - (kickoff_plays.yard_line[x.Index] % 50),axis=1)\n",
    "#     kickoff_distance[\"PlayText\"] = kickoff_distance.apply(lambda x: kickoff_plays.play_text[x.Index],axis=1)\n",
    "#     kickoff_distance[\"Distance\"] = tmp.values\n",
    "#     kickoff_distance[\"Return\"] = kickoff_distance.apply(lambda x: kickoff_plays.yards_gained[x.Index],axis=1)\n",
    "#     kickoff_distance[\"Net\"] = kickoff_distance.Distance - kickoff_distance.Return\n",
    "#     kickoff_sr = verify_division(len(kickoff_distance[kickoff_distance.Net >= 40]), len(kickoff_distance))\n",
    "#     kick_return_sr = verify_division(len(kickoff_distance[kickoff_distance.Return >= 24]), len(kickoff_distance))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'team' : [team],\n",
    "        'FGEff': [fg_eff],\n",
    "        'XPEff' : [xp_eff],\n",
    "#         'KickoffSR' : [kickoff_sr],\n",
    "#         'KickReturnSR' : [kick_return_sr]\n",
    "    })\n",
    "\n",
    "def stringify_entry(team_entry):\n",
    "    entries = team_entry.tolist()\n",
    "    return entries[0]\n",
    "\n",
    "def translate(value, inputMin, inputMax, outputMin, outputMax):\n",
    "    leftSpan = inputMax - inputMin\n",
    "    rightSpan = outputMax - outputMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - inputMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return outputMin + (valueScaled * rightSpan)\n",
    "\n",
    "def create_expl_index(team_stat_pack):\n",
    "    return translate(team_stat_pack.IsoPPPDiff, pbp_data.EqPPP.min()-pbp_data.EqPPP.max(), pbp_data.EqPPP.max()-pbp_data.EqPPP.min(), 0, 10)\n",
    "\n",
    "def create_eff_index(team_stat_pack):\n",
    "    return translate(team_stat_pack.OffSRDiff, -1, 1, 0, 10)\n",
    "\n",
    "def create_fp_index(team_stat_pack):\n",
    "    return translate(team_stat_pack.FPDiff, -50, 50, 0, 10)\n",
    "\n",
    "def create_finish_drive_index(team_stat_pack):\n",
    "    #return translate(team_stat_pack.OppPPDDiff, -7,7,0,3.5) + translate(team_stat_pack.OppRateDiff, -1, 1, 0, 4) + translate(team_stat_pack.OppSRDiff, -1,1,0,2.5)\n",
    "    return translate(team_stat_pack.OppSRDiff, -1,1,0,2.8) + translate(team_stat_pack.IsoPPPDiff, pbp_data.EqPPP.min()-pbp_data.EqPPP.max(), pbp_data.EqPPP.max()-pbp_data.EqPPP.min(), 0, 2.5) + translate(team_stat_pack.OffSRDiff, -1,1,0,2) + translate(team_stat_pack.FGEffDiff, -1,1,0,2.7)\n",
    "\n",
    "def create_turnover_index(team_stat_pack):\n",
    "    return translate(team_stat_pack.ExpTODiff - team_stat_pack.ActualTODiff, -5, 5, 0, 10)\n",
    "\n",
    "def calculate_five_factors_rating(team_stat_pack):\n",
    "    return 0.35 * create_eff_index(team_stat_pack) + 0.30 * create_expl_index(team_stat_pack) + 0.15 * create_finish_drive_index(team_stat_pack) + 0.10 * create_fp_index(team_stat_pack) + 0.10 * create_turnover_index(team_stat_pack)\n",
    "\n",
    "def createDiffs(home, away, column):\n",
    "    home[f\"{column}Diff\"] = home[column] - away[column]\n",
    "    away[f\"{column}Diff\"] = away[column] - home[column]\n",
    "\n",
    "def calculate_box_score(game_id, year):\n",
    "    game_data = games[games.id == game_id]\n",
    "    \n",
    "    if (len(game_data) == 0):\n",
    "        print(f\"Could not find basic game data for game_id {game_id} locally, checking CFB Data API\")\n",
    "        game_data = pd.read_json(retrieveRemoteCfbGame(game_id, year))\n",
    "        if (len(game_data) == 0):\n",
    "            print(f\"Could not find basic game data for game_id {game_id} on CFB Data API, bailing out\")\n",
    "            return None\n",
    "    \n",
    "    home_team = stringify_entry(game_data.home_team)\n",
    "    away_team = stringify_entry(game_data.away_team)\n",
    "    home_score = stringify_entry(game_data.home_points)\n",
    "    away_score = stringify_entry(game_data.away_points)\n",
    "    \n",
    "    game_year = stringify_entry(game_data.season)\n",
    "    game_week = stringify_entry(game_data.week)\n",
    "    \n",
    "    game_drives = drives[drives.game_id == game_id]\n",
    "    if ((len(game_drives) == 0)):\n",
    "        print(f\"Could not find drive data for game_id {game_id} locally, checking CFB Data API\")\n",
    "        if ((year == 2016) | (year == 2014)):\n",
    "            print(f\"Could not find drive data for game_id {game_id} bc of issues with 2016 and 2014 data source, bailing out\")\n",
    "            return None\n",
    "        else:\n",
    "            game_drives = pd.read_json(retrieveCfbData('drives', home_team, game_year, game_week))\n",
    "            if (len(game_drives) == 0):\n",
    "                print(f\"Could not find drive data for game_id {game_id} on CFB Data API, bailing out\")\n",
    "                return None\n",
    "            else:\n",
    "                game_drives = pd.merge(game_drives, game_data[['id','away_team','home_team']], left_on='game_id', right_on='id', how='right')\n",
    "                game_drives.rename(columns={'id_x':'drive_id'}, inplace=True)\n",
    "                game_drives.drop(['id_y'], axis = 1, inplace=True)\n",
    "                game_drives.dropna(inplace=True)\n",
    "\n",
    "                game_drives.loc[\n",
    "                    game_drives.offense == game_drives.away_team, ['start_yardline']\n",
    "                ] = 100 - game_drives.start_yardline\n",
    "                game_drives.loc[\n",
    "                    game_drives.offense == game_drives.away_team, ['end_yardline']\n",
    "                ] = 100 - game_drives.end_yardline\n",
    "    \n",
    "    game_pbp = pbp_data[pbp_data.drive_id.isin(game_drives.drive_id.tolist())]\n",
    "    if (len(game_pbp) == 0):\n",
    "        print(f\"Could not find play by play data for game_id {game_id} locally, checking CFB Data API\")\n",
    "        game_pbp = pd.read_json(retrieveCfbData('plays', home_team, game_year, game_week))\n",
    "        if (len(game_pbp) == 0):\n",
    "            print(f\"Could not find play by play data for game_id {game_id} on CFB Data API, bailing out\")\n",
    "            return None\n",
    "    \n",
    "    if 'play_explosive' not in game_pbp.columns:\n",
    "        game_pbp['play_explosive'] = game_pbp.apply(lambda x: x.yards_gained >= 15, axis=1)\n",
    "    if 'play_successful' not in game_pbp.columns:\n",
    "        game_pbp['play_successful'] = game_pbp.apply(lambda x: is_successful_vector(x), axis=1)\n",
    "    if 'EqPPP' not in game_pbp.columns:\n",
    "        game_pbp['EqPPP'] = game_pbp.apply(lambda x: ep_data.iloc[max(min(100, (x.yard_line + x.yards_gained)), 0)].ep - ep_data.iloc[max(min(100, (x.yard_line)), 0)].ep, axis=1)\n",
    "    \n",
    "    home_team_play_stats = generate_team_play_stats(game_pbp, home_team)\n",
    "    away_team_play_stats = generate_team_play_stats(game_pbp, away_team)\n",
    "    \n",
    "    home_team_drv_stats = generate_team_drive_stats(game_drives, game_pbp, game_data, home_score, home_team)\n",
    "    away_team_drv_stats = generate_team_drive_stats(game_drives, game_pbp, game_data, away_score, away_team)\n",
    "    \n",
    "    home_team_stats = pd.merge(home_team_play_stats, home_team_drv_stats, left_on=\"team\", right_on=\"team\", how='right')\n",
    "    away_team_stats = pd.merge(away_team_play_stats, away_team_drv_stats, left_on=\"team\", right_on=\"team\", how='right')\n",
    "\n",
    "    home_team_tos = generate_team_turnover_stats(game_pbp, home_team)\n",
    "    away_team_tos = generate_team_turnover_stats(game_pbp, away_team)\n",
    "    \n",
    "    home_team_stats = pd.merge(home_team_stats, home_team_tos, left_on=\"team\", right_on=\"team\", how='right')\n",
    "    away_team_stats = pd.merge(away_team_stats, away_team_tos, left_on=\"team\", right_on=\"team\", how='right')\n",
    "\n",
    "    home_team_st_stats = generate_team_special_teams_stats(game_pbp, home_team)\n",
    "    away_team_st_stats = generate_team_special_teams_stats(game_pbp, away_team)\n",
    "    \n",
    "    home_team_stats = pd.merge(home_team_stats, home_team_st_stats, left_on=\"team\", right_on=\"team\", how='right')\n",
    "    away_team_stats = pd.merge(away_team_stats, away_team_st_stats, left_on=\"team\", right_on=\"team\", how='right')\n",
    "    \n",
    "    for inpt in inputs:\n",
    "        createDiffs(home_team_stats, away_team_stats, inpt)\n",
    "    \n",
    "    home_team_stats['5FR'] = calculate_five_factors_rating(home_team_stats)\n",
    "    away_team_stats['5FR'] = calculate_five_factors_rating(away_team_stats)\n",
    "    home_team_stats['5FRDiff'] = home_team_stats['5FR'] - away_team_stats['5FR']\n",
    "    away_team_stats['5FRDiff'] = away_team_stats['5FR'] - home_team_stats['5FR']\n",
    "    \n",
    "    comb_stat_pack = away_team_stats.append(home_team_stats)\n",
    "    \n",
    "    box = pd.DataFrame({\n",
    "        \"team\" : [away_team, home_team],\n",
    "        \"Season\": [game_year, game_year],\n",
    "        \"GameID\": [game_id, game_id],\n",
    "        \"Pts\" : [away_score, home_score],\n",
    "        \"PtsDiff\" : [away_score - home_score, home_score - away_score],\n",
    "        \"CfbDataWinProb\" : [stringify_entry(game_data.away_post_win_prob),stringify_entry(game_data.home_post_win_prob)]\n",
    "    })\n",
    "    \n",
    "    box = pd.merge(box, comb_stat_pack, left_on=\"team\", right_on=\"team\", how=\"right\")\n",
    "    box.rename(columns={\"team\": \"Team\"}, inplace=True)\n",
    "    \n",
    "    return box\n",
    "\n",
    "calculate_box_score(401013183, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "game_ids = games.id.unique()\n",
    "team_list = teams[teams.conference.isin(fbs)].school.tolist()\n",
    "if ('stored_game_boxes' not in locals()) & (~path.exists(\"results/box-scores.csv\")):\n",
    "    print(f\"[Local] Box Scores are not available, generating them from scratch...\")\n",
    "    stored_game_boxes = pd.DataFrame()\n",
    "    for i, row in games.iterrows():\n",
    "        gameId = row.id\n",
    "        print(f\"[{i+1}/{len(game_ids)}] Getting game information for ESPN game_id: {gameId}...\")\n",
    "        print(f\"[{i+1}/{len(game_ids)}] Started processing game information for ESPN game_id: {gameId}...\")\n",
    "        if ((row.home_team in team_list) & (row.away_team in team_list)):\n",
    "            box_score = calculate_box_score(gameId, row.season)\n",
    "            if (box_score is not None):\n",
    "                print(f\"[{i+1}/{len(game_ids)}] Completed processing game information for ESPN game_id: {gameId}.\")\n",
    "                stored_game_boxes = stored_game_boxes.append(box_score)\n",
    "                print(f\"[{i+1}/{len(game_ids)}] Aggreggated game_id {gameId} to master data copy.\")\n",
    "            else:\n",
    "                print(f\"[{i+1}/{len(game_ids)}] Got 'None' for game_id {gameId}'s box score, skipping processing.\")\n",
    "        else:\n",
    "            print(f\"[{i+1}/{len(game_ids)}] Skipping checking game_id {gameId} bc one of the teams isn't FBS.\")\n",
    "    print(f\"[Local] Finished generating {len(stored_game_boxes)} box scores and 5FR margins from scratch.\")\n",
    "else:\n",
    "    proceed = True\n",
    "    if ('stored_game_boxes' in locals()):\n",
    "        print(f\"Relying on 'stored_game_boxes' currently loaded into memory\")\n",
    "    elif (path.exists(\"results/box-scores.csv\")):\n",
    "        print(f\"Loading box scores from file...\")\n",
    "        stored_game_boxes = pd.read_csv(\"results/box-scores.csv\", encoding=\"latin-1\")\n",
    "    else:\n",
    "        print(f\"[Local] No box scores available, bailing out...\")\n",
    "        proceed = False\n",
    "        \n",
    "    if (proceed == True):\n",
    "        print(f\"[Local] Box Scores are available in local, updating five factors ratings now...\")\n",
    "        stored_game_boxes['5FR'] = stored_game_boxes.apply(lambda row: calculate_five_factors_rating(row), axis=1)\n",
    "        print(f\"[Local] Grouping box score rows by GameID...\")\n",
    "        groups = stored_game_boxes.groupby('GameID')\n",
    "        print(f\"[Local] Generated {len(groups)} box score groups by GameID.\")\n",
    "        current = 0\n",
    "        for (name, group) in groups:\n",
    "            print(f\"[{current+1}/{len(groups)}] Updating 5FR Margin for game_id {name}...\")\n",
    "            group_ratings = group['5FR']\n",
    "            top_diff = group_ratings.iloc[0] - group_ratings.iloc[1]\n",
    "            bot_diff = group_ratings.iloc[1] - group_ratings.iloc[0]\n",
    "            group['5FRDiff'] = [top_diff, bot_diff]\n",
    "            print(f\"[{current+1}/{len(groups)}] Updated 5FR Margin for game_id {name}.\")\n",
    "            current+=1\n",
    "        print(f\"[Local] Finished updating box scores with new 5FR margins.\")\n",
    "\n",
    "if ('stored_game_boxes' in locals()):\n",
    "    print(f\"[Local] Writing updated box scores to file...\")\n",
    "    stored_game_boxes.to_csv(\"results/box-scores.csv\", index=False, sep=\",\")\n",
    "    print(f\"[Local] Wrote updated box scores to file.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stored_game_boxes.dropna(inplace=True)\n",
    "stored_game_boxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "f, axes = plt.subplots(3, figsize=(15, 15))#plt.subplots(len(inputs), figsize=(20, len(inputs) * 8))\n",
    "\n",
    "# for i in range(len(inputs)):\n",
    "#     inpt = inputs[i]\n",
    "axes[0].scatter(stored_game_boxes[f\"5FRDiff\"], stored_game_boxes.PtsDiff);\n",
    "axes[0].set_xlabel(\"5FRDiff\")\n",
    "axes[0].set_ylabel(\"Point Differential\");\n",
    "\n",
    "axes[1].scatter(0.86*stored_game_boxes[f\"OffSRDiff\"] + 0.14*stored_game_boxes[f\"IsoPPPDiff\"], stored_game_boxes.PtsDiff);\n",
    "axes[1].set_xlabel(\"OG SP+\")\n",
    "axes[1].set_ylabel(\"Point Differential\");\n",
    "\n",
    "axes[2].scatter(stored_game_boxes[f\"OffSRDiff\"] + stored_game_boxes[f\"AvgEqPPP\"], stored_game_boxes.PtsDiff);\n",
    "axes[2].set_xlabel(\"S&P with IsoPPP\")\n",
    "axes[2].set_ylabel(\"Point Differential\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_isoppp = 0.86*stored_game_boxes[f\"OffSRDiff\"] + 0.14*stored_game_boxes[f\"IsoPPPDiff\"]\n",
    "sp_eqppp = stored_game_boxes[f\"OffSRDiff\"] + stored_game_boxes[f\"AvgEqPPP\"]\n",
    "correl = pd.DataFrame(data={\"OGS&PDiff\":sp_eqppp,\"S&PIsoPPPDiff\":sp_isoppp,\"PtsDiff\":stored_game_boxes.PtsDiff})\n",
    "correl.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate outliers\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "stored_game_boxes['5fr_z_score'] = np.abs(stats.zscore(stored_game_boxes['5FRDiff']))\n",
    "stored_game_boxes['pts_z_score'] = np.abs(stats.zscore(stored_game_boxes.PtsDiff))\n",
    "stored_game_boxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = stored_game_boxes[(stored_game_boxes['5fr_z_score'] >= 3.2) | (stored_game_boxes['pts_z_score'] >= 3)]\n",
    "basis = stored_game_boxes[(stored_game_boxes['5fr_z_score'] < 3.2) & (stored_game_boxes['pts_z_score'] < 3.)]\n",
    "msk = (np.random.rand(len(basis)) < 0.80)\n",
    "train_data = basis[msk]\n",
    "test_data = basis[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    if (y_true.sum() > 0):\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    else:\n",
    "        return \"???\"\n",
    "\n",
    "inputDiffs = []\n",
    "for inpt in inputs:\n",
    "    inputDiffs.append(f\"{inpt}Diff\")\n",
    "\n",
    "model = LinearRegression().fit(train_data['5FRDiff'][:, np.newaxis], train_data.PtsDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Linear Regression: y = {model.coef_[0]:.5f}x + {model.intercept_:.5f}')\n",
    "\n",
    "preds = model.predict(test_data['5FRDiff'][:, np.newaxis])\n",
    "\n",
    "print(f\"Mean Pred Score: {preds.mean()}\")\n",
    "print(f\"Pred Std Dev: {preds.std()}\")\n",
    "\n",
    "# MAPE is not a trustworthy measurement when the mean's going to be near zero\n",
    "# mape = mean_absolute_percentage_error(test_data[\"PtsDiff\"][:, np.newaxis], preds)\n",
    "# print(f\"MAPE: {mape}%\")\n",
    "\n",
    "MAE = mean_absolute_error(test_data[\"PtsDiff\"][:, np.newaxis], preds)\n",
    "print(f\"Mean Abs Error: {MAE}\")\n",
    "\n",
    "MdnAE = median_absolute_error(test_data[\"PtsDiff\"][:, np.newaxis], preds)\n",
    "print(f\"Mdn Abs Error: {MdnAE}\")\n",
    "\n",
    "corr_matx = {\n",
    "    'ActPtsDiff' : test_data['PtsDiff'],\n",
    "}\n",
    "for inptDf in inputDiffs:\n",
    "    corr_matx[inptDf] = test_data[inptDf]\n",
    "corr_matx['5FR'] = test_data['5FR']\n",
    "corr_matx['5FRDiff'] = test_data['5FRDiff']\n",
    "corr_matx['PredPtsDiff'] = preds\n",
    "test = pd.DataFrame(corr_matx)\n",
    "\n",
    "test.corr()\n",
    "print(f'R-squared: {r2_score(test_data[\"PtsDiff\"][:,np.newaxis], preds)}\\n')\n",
    "    \n",
    "test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_game_boxes.hist(column='PtsDiff', figsize=(15,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_game_boxes.hist(column='5FR', figsize=(15,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.hist(column='PtsDiff', figsize=(15,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.hist(column='ActPtsDiff', figsize=(15,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.hist(column='PredPtsDiff', figsize=(15,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_win_prob(game_id, year):\n",
    "    sample_box = calculate_box_score(game_id, year)\n",
    "    mu = preds.mean()\n",
    "    std = preds.std()\n",
    "\n",
    "    max_box_row = sample_box[sample_box['PtsDiff'] == max(sample_box['PtsDiff'])]\n",
    "    parts = sample_box.Team.tolist()\n",
    "    print(f\"Game: {parts[0]} @ {parts[1]}\")\n",
    "    print(f\"Actual Winner: {stringify_entry(max_box_row.Team)}\")\n",
    "    print(f\"MOV: {stringify_entry(max_box_row.Team)} by {stringify_entry(max_box_row.PtsDiff)}\")\n",
    "#     print(f\"5FRDiff for {stringify_entry(max_box_row.Team)}: {stringify_entry(max_box_row['5FRDiff'])}\")\n",
    "    proj_point_diff = model.predict(max_box_row['5FRDiff'][:,np.newaxis])[0]\n",
    "    print(f\"Proj MOV: {stringify_entry(max_box_row.Team)} by {round(proj_point_diff)} (exact value: {proj_point_diff})\")\n",
    "    z = (proj_point_diff - mu) / std\n",
    "    print(f\"Z score: {z}\")\n",
    "    print(f\"Win Prob for {stringify_entry(max_box_row.Team)}: {(100 * stats.norm.cdf(z)):.2f}%\")\n",
    "    print(\"---\")\n",
    "    return stats.norm.cdf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_win_prob(401013183, 2018)  # 2018 UVA at VT for sample (this should be in the dataset, so not ideal)\n",
    "calculate_box_score(401013183, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_win_prob(401112488, 2019)  # 2019 GT at MIA\n",
    "calculate_box_score(401112488, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_win_prob(401112513, 2019)  # 2019 NCST at GT\n",
    "calculate_box_score(401112513, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_win_prob(401110863, 2019)  # 2019 Ole Miss at MSST\n",
    "calculate_box_score(401110863, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_win_prob(401012356, 2018) # 2018 LSU vs TAMU  (this should be in the dataset, so not ideal)\n",
    "calculate_box_score(401012356, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Ratings by Avg Win Prob??\n",
    "def calculate_avg_win_prob(team, year):\n",
    "#     print(team)\n",
    "    tester = stored_game_boxes[(stored_game_boxes.Team == team) & (stored_game_boxes.Season == year)]\n",
    "    if (len(tester) == 0):\n",
    "        return 0\n",
    "    pred = model.predict([[tester['5FRDiff'].mean()]])\n",
    "    mu = preds.mean()\n",
    "    std = preds.std()\n",
    "    z = (pred[0] - mu) / std\n",
    "#     print(f\"Avg Win Prob for {team}: {(100 * stats.norm.cdf(z)):.2f}%\")\n",
    "    return stats.norm.cdf(z)\n",
    "\n",
    "consider_teams = teams[teams.conference.isin(fbs)].school.tolist()\n",
    "team_wp_frame = pd.DataFrame({\"team\":consider_teams})\n",
    "team_wp_frame['avg_win_prob'] = team_wp_frame.apply(lambda x: calculate_avg_win_prob(x.team, 2019), axis=1)\n",
    "# for team in team_list:\n",
    "#     team_wp_frame = team_wp_frame.append(pd.DataFrame({\n",
    "#         'team':[team],\n",
    "#         'avg_win_prob':[calculate_avg_win_prob(team, 2019)]\n",
    "#     }))\n",
    "team_wp_frame['games'] = team_wp_frame.apply(lambda x: len(games[(games.season == 2019) & ((games.home_team == x.team) | (games.away_team == x.team))]), axis=1)\n",
    "team_wp_frame['proj_wins'] = round(team_wp_frame.avg_win_prob * team_wp_frame.games)\n",
    "team_wp_frame['proj_losses'] = team_wp_frame.games - team_wp_frame['proj_wins']\n",
    "team_wp_frame = team_wp_frame.sort_values(by=['avg_win_prob','games'], ascending=False)\n",
    "team_wp_frame.index = range(1,len(team_wp_frame.team)+1)\n",
    "team_wp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Ratings by Avg Win Prob??\n",
    "def calculate_z(item, mu, std):\n",
    "    return (item - mu) / std\n",
    "\n",
    "def calculate_second_order_wins(team, year):\n",
    "#     print(team)\n",
    "    tester = stored_game_boxes[(stored_game_boxes.Team == team) & (stored_game_boxes.Season == year)]\n",
    "    if (len(tester) == 0):\n",
    "        return 0\n",
    "    pred = model.predict(tester['5FRDiff'][:,np.newaxis])\n",
    "    mu = preds.mean()\n",
    "    std = preds.std()\n",
    "    zs = np.vectorize(calculate_z)(pred, mu, std)\n",
    "    probs = stats.norm.cdf(zs)\n",
    "    return probs.sum()\n",
    "\n",
    "team_second_order_frame = pd.DataFrame({\"team\":consider_teams})\n",
    "team_second_order_frame[\"second_order_wins\"] = team_second_order_frame.apply(lambda x: calculate_second_order_wins(x.team, 2019),axis=1)\n",
    "team_second_order_frame[\"second_order_losses\"] = team_second_order_frame.apply(lambda x: len(games[((games.home_team == x.team) | (games.away_team == x.team)) & (games.season == 2019)]) - x.second_order_wins,axis=1)\n",
    "team_second_order_frame.sort_values(by=['second_order_wins'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matchup Predictor?\n",
    "def predict_matchup(team1, team2, year):\n",
    "    team1_avg_ffr = stored_game_boxes[(stored_game_boxes.Team == team1) & (stored_game_boxes.Season == year)]['5FR'][-4:].mean()\n",
    "    team2_avg_ffr = stored_game_boxes[(stored_game_boxes.Team == team2) & (stored_game_boxes.Season == year)]['5FR'][-4:].mean()\n",
    "    if (~(teams[teams.school == team1].conference.isin(p5).all())):\n",
    "        team1_avg_ffr *= 0.85 # arbitrary\n",
    "    if (~(teams[teams.school == team2].conference.isin(p5).all())):\n",
    "        team2_avg_ffr *= 0.85 # arbitrary\n",
    "    ffr_diff = team1_avg_ffr - team2_avg_ffr # assumes team_1 is home\n",
    "    pred = model.predict([[ffr_diff]])\n",
    "    mu = preds.mean()\n",
    "    std = preds.std()\n",
    "    z = (pred[0] - mu) / std\n",
    "    win_prob = stats.norm.cdf(z)\n",
    "    return [win_prob, pred[0]]\n",
    "\n",
    "predict_matchup('Georgia Tech','Clemson',2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_triples = [\n",
    "    ['LSU','Oklahoma',11], # CFP Semifinal: Peach Bowl\n",
    "    ['Clemson','Ohio State',2.5], # CFP Semifinal: Fiesta Bowl\n",
    "    ['Penn State','Memphis',7], # Cotton Bowl\n",
    "    ['Florida','Virginia',14], # Orange Bowl\n",
    "    ['Wisconsin','Oregon',2.5], # Rose Bowl\n",
    "    ['Georgia','Baylor',7.5] # Sugar Bowl\n",
    "]\n",
    "\n",
    "bets = pd.DataFrame()\n",
    "\n",
    "for data in team_triples:\n",
    "    team1 = data[0]\n",
    "    team2 = data[1]\n",
    "    spread = data[2] # team 1 is always favorite\n",
    "    predictor = predict_matchup(team1, team2, 2019)\n",
    "    bets = bets.append(pd.DataFrame({\n",
    "        \"favorite\": [team1],\n",
    "        \"opponent\" : [team2],\n",
    "        \"spread\" : [spread],\n",
    "        \"proj_MOV\" : [predictor[1]],\n",
    "        \"proj_win_prob\" : [predictor[0]],\n",
    "        \"proj_cover_status\" : [predictor[1] > spread],\n",
    "        \"ml_pick\": [team1 if (predictor[1] > 0) else team2],\n",
    "        \"ats_pick\": [team1 if (predictor[1] > spread) else team2]\n",
    "    }))\n",
    "    \n",
    "bets.sort_values(by=['proj_cover_status','proj_MOV'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_win_prob(401112521, 2019)  # 2019 VT @ UVA\n",
    "calculate_box_score(401112521, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_win_prob(401112475, 2019) # 2019 UNC at GT\n",
    "calculate_box_score(401112475, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_win_prob(401112498, 2019) # 2019 Pitt at GT\n",
    "calculate_box_score(401112498, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_win_prob(401110865, 2019) # 2019 Iron Bowl\n",
    "calculate_box_score(401110865, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_win_prob(401110867, 2019)\n",
    "calculate_box_score(401110867, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_opponent(box, team):\n",
    "    return box[box.Team != team].Team.tolist()[0]\n",
    "\n",
    "def filter_MOV(box, team):\n",
    "    return box[box.Team == team].PtsDiff.tolist()[0]\n",
    "\n",
    "def clean_win_prob(row):\n",
    "    prob = generate_win_prob(row.GameID, 2019)\n",
    "    return prob if row.ActualMOV > 0 else 1-prob\n",
    "\n",
    "def retrieve_win_probs(team, year):\n",
    "    game_ids = games[((games.home_team == team) | (games.away_team == team)) & (games.season == year)].id\n",
    "    frame = pd.DataFrame({\"GameID\":game_ids,\"Year\":year})\n",
    "    frame['Team'] = team\n",
    "    frame['Opponent'] = frame.apply(lambda y: filter_opponent(calculate_box_score(y.GameID, 2019),team), axis=1)\n",
    "    frame['ActualMOV'] = frame.apply(lambda y: filter_MOV(calculate_box_score(y.GameID, 2019),team), axis=1)\n",
    "    frame['PostGameWinProb'] = frame.apply(lambda x: clean_win_prob(x) * 100, axis=1)\n",
    "    return frame\n",
    "\n",
    "retrieve_win_probs(\"Georgia Tech\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from datetime import datetime\n",
    "# now = datetime.now()\n",
    "# filename = now.strftime(\"%d-%b-%Y-%H:%M:%S\")\n",
    "# pkl_filename = f\"results/wp_model-{filename}.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
